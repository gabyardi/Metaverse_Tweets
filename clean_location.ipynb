{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0add5807-dca3-4239-beea-262ba11d60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_sm\n",
    "#!pip install geopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import NLP\n",
    "from dataprep.clean import validate_country\n",
    "import altair as alt\n",
    "# instantiate one\n",
    "import spacy \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#import geopy.geocoder\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import folium \n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617cfb51-732f-401c-96c0-06b36acc227d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 13)\n"
     ]
    }
   ],
   "source": [
    "# This code is reading from the original csv file that is 1000 rows long \n",
    "df = pd.read_csv('metaverse_tweets.csv')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb238a-741a-4ba4-b831-2ac2673fc88c",
   "metadata": {},
   "source": [
    "## Cleaning Twitter Location Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b011eb-dc2e-4d62-9555-e2ac5274eaff",
   "metadata": {},
   "source": [
    "Removing #'s from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab2f9ab0-8f09-477a-841c-6cf815eeddd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diep Ngoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-22 09:53:23+00:00</td>\n",
       "      <td>162</td>\n",
       "      <td>129</td>\n",
       "      <td>1816</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:46+00:00</td>\n",
       "      <td>@KingArthurrNFT My choice is #Elemon ğŸ˜ŠğŸ¤©ğŸ˜ğŸ¥°\\n#BS...</td>\n",
       "      <td>['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duncs</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NFT's + Crypto + Metaverse + Outdoors + Goodtimes</td>\n",
       "      <td>2012-11-28 01:47:19+00:00</td>\n",
       "      <td>745</td>\n",
       "      <td>1363</td>\n",
       "      <td>2583</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:33+00:00</td>\n",
       "      <td>Can't wait to hear this #Bapesclan \\n\\n#BapesM...</td>\n",
       "      <td>['Bapesclan', 'BapesMetavestor', 'Metaverse']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Putik Gita</td>\n",
       "      <td>Banyuwangi, Indonesia</td>\n",
       "      <td>just ordinary woman</td>\n",
       "      <td>2016-04-07 03:31:10+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>130</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:26+00:00</td>\n",
       "      <td>@SuperStarPad @binance @Nuls good project.. ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...</td>\n",
       "      <td>2021-10-15 18:21:33+00:00</td>\n",
       "      <td>2355</td>\n",
       "      <td>3349</td>\n",
       "      <td>8550</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:13+00:00</td>\n",
       "      <td>Starts Trading on Uniswap and XT Exchanges Feb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ilyass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cool</td>\n",
       "      <td>2021-07-30 15:48:01+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>115</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:05+00:00</td>\n",
       "      <td>@hustleofwargame #P2E #GameFi #Metaverse #Game...</td>\n",
       "      <td>['P2E', 'GameFi', 'Metaverse', 'GameNFTs', 'Bl...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:04+00:00</td>\n",
       "      <td>@supertobi64 #MiniKishu is the next BIG projec...</td>\n",
       "      <td>['MiniKishu', 'BSC', 'gaming', 'staking']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Diep Ngoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-22 09:53:23+00:00</td>\n",
       "      <td>162</td>\n",
       "      <td>129</td>\n",
       "      <td>1816</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:58+00:00</td>\n",
       "      <td>@aegean2356 My choice is #Elemon ğŸ¥°ğŸ¤©ğŸ’–ğŸ’—ğŸ’\\n#BSC  ...</td>\n",
       "      <td>['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸</td>\n",
       "      <td>Atlanta, GAğŸ“</td>\n",
       "      <td>ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...</td>\n",
       "      <td>2013-06-03 18:46:28+00:00</td>\n",
       "      <td>3965</td>\n",
       "      <td>4975</td>\n",
       "      <td>119194</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:57+00:00</td>\n",
       "      <td>NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:46+00:00</td>\n",
       "      <td>@PeeGee05 @MatrixETF @DEnergizer645 @anietieet...</td>\n",
       "      <td>['MiniKishu', 'BSC']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rabby78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Like comments flow korben plz</td>\n",
       "      <td>2021-08-30 19:02:38+00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>1166</td>\n",
       "      <td>1767</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:32+00:00</td>\n",
       "      <td>The project is great and this projector has a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Duncs</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NFT's + Crypto + Metaverse + Outdoors + Goodtimes</td>\n",
       "      <td>2012-11-28 01:47:19+00:00</td>\n",
       "      <td>745</td>\n",
       "      <td>1363</td>\n",
       "      <td>2583</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:22+00:00</td>\n",
       "      <td>Cant wait for #spacebapes \\n\\n#bapesclan #Meta...</td>\n",
       "      <td>['spacebapes', 'bapesclan', 'Metaverse', 'bape...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Benjamin Carr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creator of RnB Collection NFTs, inspired by my...</td>\n",
       "      <td>2021-08-23 11:29:12+00:00</td>\n",
       "      <td>520</td>\n",
       "      <td>711</td>\n",
       "      <td>10643</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:05+00:00</td>\n",
       "      <td>@NFTGalIery AidiVerse: Create, Play and Prospe...</td>\n",
       "      <td>['metaverse']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Art</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I sell various products such as clothes, sweat...</td>\n",
       "      <td>2021-05-29 18:44:35+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>209</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:57:57+00:00</td>\n",
       "      <td>@uranium_digital my first ntf was the result o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Diep Ngoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-22 09:53:23+00:00</td>\n",
       "      <td>162</td>\n",
       "      <td>129</td>\n",
       "      <td>1816</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:57:50+00:00</td>\n",
       "      <td>@ElemonGame ğŸ‘ğŸ‘ğŸ‘ it's greatğŸ¥°ğŸ˜ğŸ¥°\\n#BSC  #NFT  #Ga...</td>\n",
       "      <td>['BSC', 'NFT', 'GameFi', 'Metaverse', 'Elemon'...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bacon#8167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-03 08:16:26+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>128</td>\n",
       "      <td>232</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:53+00:00</td>\n",
       "      <td>Check out the roadmap of the wandering nugs.\\n...</td>\n",
       "      <td>['Metaverse', 'AugmentedReality', 'NFT', 'pass...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NFTcrawler.eth</td>\n",
       "      <td>NFTverse</td>\n",
       "      <td>#mww</td>\n",
       "      <td>2009-07-04 13:44:10+00:00</td>\n",
       "      <td>193</td>\n",
       "      <td>97</td>\n",
       "      <td>347</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:32+00:00</td>\n",
       "      <td>@whitesandsgame @nftworldsNFT White Sands will...</td>\n",
       "      <td>['Metaverse']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HQ Muhammad Ashikur Rahman</td>\n",
       "      <td>Sreemongal</td>\n",
       "      <td>https://t.co/YXClUUDjtR\\n\\nBismillahir Rahmani...</td>\n",
       "      <td>2021-04-21 14:29:40+00:00</td>\n",
       "      <td>445</td>\n",
       "      <td>2239</td>\n",
       "      <td>2663</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:27+00:00</td>\n",
       "      <td>@TAROVERSEcom I've participated with the rules...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0x888nft</td>\n",
       "      <td>Radioactive world</td>\n",
       "      <td>0x888nft.eth:\\n#WomenOfCrypto-#784 (42/8888)\\n...</td>\n",
       "      <td>2022-01-15 00:33:52+00:00</td>\n",
       "      <td>193</td>\n",
       "      <td>35</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:17+00:00</td>\n",
       "      <td>In the world of #RadioactiveApes, don't forget...</td>\n",
       "      <td>['RadioactiveApes', 'nfts', 'NFTCommunity', '3...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meta Monsters Club</td>\n",
       "      <td>United States</td>\n",
       "      <td>MMC is a collection of 6,000 generative NFTs, ...</td>\n",
       "      <td>2021-12-05 17:19:46+00:00</td>\n",
       "      <td>141</td>\n",
       "      <td>122</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:14+00:00</td>\n",
       "      <td>âœ… Follow us to grab your monster when it's on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MetaMonstersClub</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Diep Ngoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-22 09:53:23+00:00</td>\n",
       "      <td>162</td>\n",
       "      <td>129</td>\n",
       "      <td>1816</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:08+00:00</td>\n",
       "      <td>@atimetass I choose #Elemon ğŸ¥°ğŸ¤©ğŸ˜ŠğŸ¤©\\n#BSC  #NFT  ...</td>\n",
       "      <td>['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_name          user_location  \\\n",
       "0                    Diep Ngoc                    NaN   \n",
       "1                        Duncs   Melbourne, Australia   \n",
       "2                   Putik Gita  Banyuwangi, Indonesia   \n",
       "3                ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘      Dhaka, Bangladesh   \n",
       "4                       Ilyass                    NaN   \n",
       "5                       LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "6                    Diep Ngoc                    NaN   \n",
       "7                      ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸           Atlanta, GAğŸ“   \n",
       "8                       LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "9                      Rabby78                    NaN   \n",
       "10                       Duncs   Melbourne, Australia   \n",
       "11               Benjamin Carr                    NaN   \n",
       "12                      My Art                    NaN   \n",
       "13                   Diep Ngoc                    NaN   \n",
       "14                  Bacon#8167                    NaN   \n",
       "15              NFTcrawler.eth               NFTverse   \n",
       "16  HQ Muhammad Ashikur Rahman             Sreemongal   \n",
       "17                    0x888nft      Radioactive world   \n",
       "18          Meta Monsters Club          United States   \n",
       "19                   Diep Ngoc                    NaN   \n",
       "\n",
       "                                     user_description  \\\n",
       "0                                                 NaN   \n",
       "1   NFT's + Crypto + Metaverse + Outdoors + Goodtimes   \n",
       "2                                 just ordinary woman   \n",
       "3   ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...   \n",
       "4                                                Cool   \n",
       "5   Anatomist||Man utd faithful || Music freak || ...   \n",
       "6                                                 NaN   \n",
       "7   ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...   \n",
       "8   Anatomist||Man utd faithful || Music freak || ...   \n",
       "9                       Like comments flow korben plz   \n",
       "10  NFT's + Crypto + Metaverse + Outdoors + Goodtimes   \n",
       "11  Creator of RnB Collection NFTs, inspired by my...   \n",
       "12  I sell various products such as clothes, sweat...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                               #mww   \n",
       "16  https://t.co/YXClUUDjtR\\n\\nBismillahir Rahmani...   \n",
       "17  0x888nft.eth:\\n#WomenOfCrypto-#784 (42/8888)\\n...   \n",
       "18  MMC is a collection of 6,000 generative NFTs, ...   \n",
       "19                                                NaN   \n",
       "\n",
       "                 user_created  user_followers  user_friends  user_favourites  \\\n",
       "0   2021-08-22 09:53:23+00:00             162           129             1816   \n",
       "1   2012-11-28 01:47:19+00:00             745          1363             2583   \n",
       "2   2016-04-07 03:31:10+00:00              21           130               65   \n",
       "3   2021-10-15 18:21:33+00:00            2355          3349             8550   \n",
       "4   2021-07-30 15:48:01+00:00               4           130              115   \n",
       "5   2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "6   2021-08-22 09:53:23+00:00             162           129             1816   \n",
       "7   2013-06-03 18:46:28+00:00            3965          4975           119194   \n",
       "8   2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "9   2021-08-30 19:02:38+00:00              30          1166             1767   \n",
       "10  2012-11-28 01:47:19+00:00             745          1363             2583   \n",
       "11  2021-08-23 11:29:12+00:00             520           711            10643   \n",
       "12  2021-05-29 18:44:35+00:00               3           209              304   \n",
       "13  2021-08-22 09:53:23+00:00             162           129             1816   \n",
       "14  2021-11-03 08:16:26+00:00              22           128              232   \n",
       "15  2009-07-04 13:44:10+00:00             193            97              347   \n",
       "16  2021-04-21 14:29:40+00:00             445          2239             2663   \n",
       "17  2022-01-15 00:33:52+00:00             193            35              110   \n",
       "18  2021-12-05 17:19:46+00:00             141           122               66   \n",
       "19  2021-08-22 09:53:23+00:00             162           129             1816   \n",
       "\n",
       "    user_verified                       date  \\\n",
       "0           False  2022-02-27 23:59:46+00:00   \n",
       "1           False  2022-02-27 23:59:33+00:00   \n",
       "2           False  2022-02-27 23:59:26+00:00   \n",
       "3           False  2022-02-27 23:59:13+00:00   \n",
       "4           False  2022-02-27 23:59:05+00:00   \n",
       "5           False  2022-02-27 23:59:04+00:00   \n",
       "6           False  2022-02-27 23:58:58+00:00   \n",
       "7           False  2022-02-27 23:58:57+00:00   \n",
       "8           False  2022-02-27 23:58:46+00:00   \n",
       "9           False  2022-02-27 23:58:32+00:00   \n",
       "10          False  2022-02-27 23:58:22+00:00   \n",
       "11          False  2022-02-27 23:58:05+00:00   \n",
       "12          False  2022-02-27 23:57:57+00:00   \n",
       "13          False  2022-02-27 23:57:50+00:00   \n",
       "14          False  2022-02-27 23:56:53+00:00   \n",
       "15          False  2022-02-27 23:56:32+00:00   \n",
       "16          False  2022-02-27 23:56:27+00:00   \n",
       "17          False  2022-02-27 23:56:17+00:00   \n",
       "18          False  2022-02-27 23:56:14+00:00   \n",
       "19          False  2022-02-27 23:56:08+00:00   \n",
       "\n",
       "                                                 text  \\\n",
       "0   @KingArthurrNFT My choice is #Elemon ğŸ˜ŠğŸ¤©ğŸ˜ğŸ¥°\\n#BS...   \n",
       "1   Can't wait to hear this #Bapesclan \\n\\n#BapesM...   \n",
       "2   @SuperStarPad @binance @Nuls good project.. ho...   \n",
       "3   Starts Trading on Uniswap and XT Exchanges Feb...   \n",
       "4   @hustleofwargame #P2E #GameFi #Metaverse #Game...   \n",
       "5   @supertobi64 #MiniKishu is the next BIG projec...   \n",
       "6   @aegean2356 My choice is #Elemon ğŸ¥°ğŸ¤©ğŸ’–ğŸ’—ğŸ’\\n#BSC  ...   \n",
       "7   NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...   \n",
       "8   @PeeGee05 @MatrixETF @DEnergizer645 @anietieet...   \n",
       "9   The project is great and this projector has a ...   \n",
       "10  Cant wait for #spacebapes \\n\\n#bapesclan #Meta...   \n",
       "11  @NFTGalIery AidiVerse: Create, Play and Prospe...   \n",
       "12  @uranium_digital my first ntf was the result o...   \n",
       "13  @ElemonGame ğŸ‘ğŸ‘ğŸ‘ it's greatğŸ¥°ğŸ˜ğŸ¥°\\n#BSC  #NFT  #Ga...   \n",
       "14  Check out the roadmap of the wandering nugs.\\n...   \n",
       "15  @whitesandsgame @nftworldsNFT White Sands will...   \n",
       "16  @TAROVERSEcom I've participated with the rules...   \n",
       "17  In the world of #RadioactiveApes, don't forget...   \n",
       "18  âœ… Follow us to grab your monster when it's on ...   \n",
       "19  @atimetass I choose #Elemon ğŸ¥°ğŸ¤©ğŸ˜ŠğŸ¤©\\n#BSC  #NFT  ...   \n",
       "\n",
       "                                             hashtags               source  \\\n",
       "0   ['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...  Twitter for Android   \n",
       "1       ['Bapesclan', 'BapesMetavestor', 'Metaverse']      Twitter Web App   \n",
       "2                                                 NaN  Twitter for Android   \n",
       "3                                                 NaN      Twitter Web App   \n",
       "4   ['P2E', 'GameFi', 'Metaverse', 'GameNFTs', 'Bl...  Twitter for Android   \n",
       "5           ['MiniKishu', 'BSC', 'gaming', 'staking']   Twitter for iPhone   \n",
       "6   ['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...  Twitter for Android   \n",
       "7                                                 NaN   Twitter for iPhone   \n",
       "8                                ['MiniKishu', 'BSC']   Twitter for iPhone   \n",
       "9                                                 NaN  Twitter for Android   \n",
       "10  ['spacebapes', 'bapesclan', 'Metaverse', 'bape...      Twitter Web App   \n",
       "11                                      ['metaverse']   Twitter for iPhone   \n",
       "12                                                NaN      Twitter Web App   \n",
       "13  ['BSC', 'NFT', 'GameFi', 'Metaverse', 'Elemon'...  Twitter for Android   \n",
       "14  ['Metaverse', 'AugmentedReality', 'NFT', 'pass...      Twitter Web App   \n",
       "15                                      ['Metaverse']      Twitter Web App   \n",
       "16                                                NaN      Twitter Web App   \n",
       "17  ['RadioactiveApes', 'nfts', 'NFTCommunity', '3...  Twitter for Android   \n",
       "18                                                NaN     MetaMonstersClub   \n",
       "19  ['Elemon', 'BSC', 'NFT', 'GameFi', 'Metaverse'...  Twitter for Android   \n",
       "\n",
       "    is_retweet  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  \n",
       "6        False  \n",
       "7        False  \n",
       "8        False  \n",
       "9        False  \n",
       "10       False  \n",
       "11       False  \n",
       "12       False  \n",
       "13       False  \n",
       "14       False  \n",
       "15       False  \n",
       "16       False  \n",
       "17       False  \n",
       "18       False  \n",
       "19       False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_location.astype(str)\n",
    "df = df[~df.user_location.str.contains(\"#\", na=False)] \n",
    "df.head(20)                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676d61b-e79d-47d8-9df4-a7fbb91c9043",
   "metadata": {},
   "source": [
    "Removing Na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef35783e-9088-428f-80a1-1e06b64696f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"user_location\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bf9b1",
   "metadata": {},
   "source": [
    "## Getting rid of the emojis in the location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b61f9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duncs</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NFT's + Crypto + Metaverse + Outdoors + Goodtimes</td>\n",
       "      <td>2012-11-28 01:47:19+00:00</td>\n",
       "      <td>745</td>\n",
       "      <td>1363</td>\n",
       "      <td>2583</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:33+00:00</td>\n",
       "      <td>Can't wait to hear this #Bapesclan \\n\\n#BapesM...</td>\n",
       "      <td>['Bapesclan', 'BapesMetavestor', 'Metaverse']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Putik Gita</td>\n",
       "      <td>Banyuwangi, Indonesia</td>\n",
       "      <td>just ordinary woman</td>\n",
       "      <td>2016-04-07 03:31:10+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>130</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:26+00:00</td>\n",
       "      <td>@SuperStarPad @binance @Nuls good project.. ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...</td>\n",
       "      <td>2021-10-15 18:21:33+00:00</td>\n",
       "      <td>2355</td>\n",
       "      <td>3349</td>\n",
       "      <td>8550</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:13+00:00</td>\n",
       "      <td>Starts Trading on Uniswap and XT Exchanges Feb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:04+00:00</td>\n",
       "      <td>@supertobi64 #MiniKishu is the next BIG projec...</td>\n",
       "      <td>['MiniKishu', 'BSC', 'gaming', 'staking']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...</td>\n",
       "      <td>2013-06-03 18:46:28+00:00</td>\n",
       "      <td>3965</td>\n",
       "      <td>4975</td>\n",
       "      <td>119194</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:57+00:00</td>\n",
       "      <td>NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:46+00:00</td>\n",
       "      <td>@PeeGee05 @MatrixETF @DEnergizer645 @anietieet...</td>\n",
       "      <td>['MiniKishu', 'BSC']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Duncs</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NFT's + Crypto + Metaverse + Outdoors + Goodtimes</td>\n",
       "      <td>2012-11-28 01:47:19+00:00</td>\n",
       "      <td>745</td>\n",
       "      <td>1363</td>\n",
       "      <td>2583</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:22+00:00</td>\n",
       "      <td>Cant wait for #spacebapes \\n\\n#bapesclan #Meta...</td>\n",
       "      <td>['spacebapes', 'bapesclan', 'Metaverse', 'bape...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NFTcrawler.eth</td>\n",
       "      <td>NFTverse</td>\n",
       "      <td>#mww</td>\n",
       "      <td>2009-07-04 13:44:10+00:00</td>\n",
       "      <td>193</td>\n",
       "      <td>97</td>\n",
       "      <td>347</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:32+00:00</td>\n",
       "      <td>@whitesandsgame @nftworldsNFT White Sands will...</td>\n",
       "      <td>['Metaverse']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HQ Muhammad Ashikur Rahman</td>\n",
       "      <td>Sreemongal</td>\n",
       "      <td>https://t.co/YXClUUDjtR\\n\\nBismillahir Rahmani...</td>\n",
       "      <td>2021-04-21 14:29:40+00:00</td>\n",
       "      <td>445</td>\n",
       "      <td>2239</td>\n",
       "      <td>2663</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:27+00:00</td>\n",
       "      <td>@TAROVERSEcom I've participated with the rules...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0x888nft</td>\n",
       "      <td>Radioactive world</td>\n",
       "      <td>0x888nft.eth:\\n#WomenOfCrypto-#784 (42/8888)\\n...</td>\n",
       "      <td>2022-01-15 00:33:52+00:00</td>\n",
       "      <td>193</td>\n",
       "      <td>35</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:17+00:00</td>\n",
       "      <td>In the world of #RadioactiveApes, don't forget...</td>\n",
       "      <td>['RadioactiveApes', 'nfts', 'NFTCommunity', '3...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Meta Monsters Club</td>\n",
       "      <td>United States</td>\n",
       "      <td>MMC is a collection of 6,000 generative NFTs, ...</td>\n",
       "      <td>2021-12-05 17:19:46+00:00</td>\n",
       "      <td>141</td>\n",
       "      <td>122</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:14+00:00</td>\n",
       "      <td>âœ… Follow us to grab your monster when it's on ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MetaMonstersClub</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:07+00:00</td>\n",
       "      <td>@mayordraw @_BillionAireSon @LadyofCrypto1 @Da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FogWalkerXá´ºá¶ áµ€</td>\n",
       "      <td>South Germany</td>\n",
       "      <td>Artist ğŸ¨ &amp; Collector ğŸ–¼ï¸\\n#NFT #nftartist #nftc...</td>\n",
       "      <td>2021-09-16 17:29:37+00:00</td>\n",
       "      <td>646</td>\n",
       "      <td>517</td>\n",
       "      <td>7755</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:56:00+00:00</td>\n",
       "      <td>Boars Lost in Art ğŸ— ğŸ¨ ğŸ–¼\\n\\n555 AI Generated #N...</td>\n",
       "      <td>['NFTs']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:49+00:00</td>\n",
       "      <td>@metaturca #MiniKishu is the next BIG project ...</td>\n",
       "      <td>['MiniKishu', 'BSC', 'gaming', 'staking', 'NFT']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Topcat</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>hunting gems #bscGems https://t.co/DNNPEUE1Gy</td>\n",
       "      <td>2021-03-09 15:58:44+00:00</td>\n",
       "      <td>3909</td>\n",
       "      <td>710</td>\n",
       "      <td>187</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:41+00:00</td>\n",
       "      <td>@ConnectorCoin bringing celebrities onboard fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:32+00:00</td>\n",
       "      <td>@LycanFinance #MiniKishu is the next BIG proje...</td>\n",
       "      <td>['MiniKishu', 'BSC', 'gaming', 'staking']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>beholder27</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>My imagination is connected to a super conscio...</td>\n",
       "      <td>2020-09-23 14:10:41+00:00</td>\n",
       "      <td>108</td>\n",
       "      <td>73</td>\n",
       "      <td>1220</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:27+00:00</td>\n",
       "      <td>THIS PIECE NEEDS A BUYER ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\\n\\nGASLESS store...</td>\n",
       "      <td>['NFT', 'NFTs', 'nftcollector', 'NFTinvestor',...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>beholder27</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>My imagination is connected to a super conscio...</td>\n",
       "      <td>2020-09-23 14:10:41+00:00</td>\n",
       "      <td>108</td>\n",
       "      <td>73</td>\n",
       "      <td>1220</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:17+00:00</td>\n",
       "      <td>THIS PIECE NEEDS A BUYER ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\\n\\nGASLESS store...</td>\n",
       "      <td>['NFT', 'NFTs', 'nftcollector', 'NFTinvestor',...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:13+00:00</td>\n",
       "      <td>@FeggyPebbles @binance @FEGchris @Crypt0mummy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>YAWPster âš›ï¸</td>\n",
       "      <td>COSMOS</td>\n",
       "      <td>#entrepreneur economist turned #NFT collector ...</td>\n",
       "      <td>2013-02-27 01:10:49+00:00</td>\n",
       "      <td>537</td>\n",
       "      <td>1486</td>\n",
       "      <td>8218</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:55:09+00:00</td>\n",
       "      <td>#NFTMarketplace launch tomorrow!  #Yawp ğŸš€  #IB...</td>\n",
       "      <td>['NFTMarketplace', 'Yawp', 'IBCgang']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_name          user_location  \\\n",
       "1                        Duncs   Melbourne, Australia   \n",
       "2                   Putik Gita  Banyuwangi, Indonesia   \n",
       "3                ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘      Dhaka, Bangladesh   \n",
       "5                       LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "7                      ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸            Atlanta, GA   \n",
       "8                       LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "10                       Duncs   Melbourne, Australia   \n",
       "15              NFTcrawler.eth               NFTverse   \n",
       "16  HQ Muhammad Ashikur Rahman             Sreemongal   \n",
       "17                    0x888nft      Radioactive world   \n",
       "18          Meta Monsters Club          United States   \n",
       "20                      LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "21               FogWalkerXá´ºá¶ áµ€          South Germany   \n",
       "22                      LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "23                      Topcat         United Kingdom   \n",
       "24                      LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "25                  beholder27          New York, USA   \n",
       "27                  beholder27          New York, USA   \n",
       "28                      LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "30                 YAWPster âš›ï¸                COSMOS    \n",
       "\n",
       "                                     user_description  \\\n",
       "1   NFT's + Crypto + Metaverse + Outdoors + Goodtimes   \n",
       "2                                 just ordinary woman   \n",
       "3   ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...   \n",
       "5   Anatomist||Man utd faithful || Music freak || ...   \n",
       "7   ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...   \n",
       "8   Anatomist||Man utd faithful || Music freak || ...   \n",
       "10  NFT's + Crypto + Metaverse + Outdoors + Goodtimes   \n",
       "15                                               #mww   \n",
       "16  https://t.co/YXClUUDjtR\\n\\nBismillahir Rahmani...   \n",
       "17  0x888nft.eth:\\n#WomenOfCrypto-#784 (42/8888)\\n...   \n",
       "18  MMC is a collection of 6,000 generative NFTs, ...   \n",
       "20  Anatomist||Man utd faithful || Music freak || ...   \n",
       "21  Artist ğŸ¨ & Collector ğŸ–¼ï¸\\n#NFT #nftartist #nftc...   \n",
       "22  Anatomist||Man utd faithful || Music freak || ...   \n",
       "23      hunting gems #bscGems https://t.co/DNNPEUE1Gy   \n",
       "24  Anatomist||Man utd faithful || Music freak || ...   \n",
       "25  My imagination is connected to a super conscio...   \n",
       "27  My imagination is connected to a super conscio...   \n",
       "28  Anatomist||Man utd faithful || Music freak || ...   \n",
       "30  #entrepreneur economist turned #NFT collector ...   \n",
       "\n",
       "                 user_created  user_followers  user_friends  user_favourites  \\\n",
       "1   2012-11-28 01:47:19+00:00             745          1363             2583   \n",
       "2   2016-04-07 03:31:10+00:00              21           130               65   \n",
       "3   2021-10-15 18:21:33+00:00            2355          3349             8550   \n",
       "5   2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "7   2013-06-03 18:46:28+00:00            3965          4975           119194   \n",
       "8   2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "10  2012-11-28 01:47:19+00:00             745          1363             2583   \n",
       "15  2009-07-04 13:44:10+00:00             193            97              347   \n",
       "16  2021-04-21 14:29:40+00:00             445          2239             2663   \n",
       "17  2022-01-15 00:33:52+00:00             193            35              110   \n",
       "18  2021-12-05 17:19:46+00:00             141           122               66   \n",
       "20  2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "21  2021-09-16 17:29:37+00:00             646           517             7755   \n",
       "22  2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "23  2021-03-09 15:58:44+00:00            3909           710              187   \n",
       "24  2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "25  2020-09-23 14:10:41+00:00             108            73             1220   \n",
       "27  2020-09-23 14:10:41+00:00             108            73             1220   \n",
       "28  2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "30  2013-02-27 01:10:49+00:00             537          1486             8218   \n",
       "\n",
       "    user_verified                       date  \\\n",
       "1           False  2022-02-27 23:59:33+00:00   \n",
       "2           False  2022-02-27 23:59:26+00:00   \n",
       "3           False  2022-02-27 23:59:13+00:00   \n",
       "5           False  2022-02-27 23:59:04+00:00   \n",
       "7           False  2022-02-27 23:58:57+00:00   \n",
       "8           False  2022-02-27 23:58:46+00:00   \n",
       "10          False  2022-02-27 23:58:22+00:00   \n",
       "15          False  2022-02-27 23:56:32+00:00   \n",
       "16          False  2022-02-27 23:56:27+00:00   \n",
       "17          False  2022-02-27 23:56:17+00:00   \n",
       "18          False  2022-02-27 23:56:14+00:00   \n",
       "20          False  2022-02-27 23:56:07+00:00   \n",
       "21          False  2022-02-27 23:56:00+00:00   \n",
       "22          False  2022-02-27 23:55:49+00:00   \n",
       "23          False  2022-02-27 23:55:41+00:00   \n",
       "24          False  2022-02-27 23:55:32+00:00   \n",
       "25          False  2022-02-27 23:55:27+00:00   \n",
       "27          False  2022-02-27 23:55:17+00:00   \n",
       "28          False  2022-02-27 23:55:13+00:00   \n",
       "30          False  2022-02-27 23:55:09+00:00   \n",
       "\n",
       "                                                 text  \\\n",
       "1   Can't wait to hear this #Bapesclan \\n\\n#BapesM...   \n",
       "2   @SuperStarPad @binance @Nuls good project.. ho...   \n",
       "3   Starts Trading on Uniswap and XT Exchanges Feb...   \n",
       "5   @supertobi64 #MiniKishu is the next BIG projec...   \n",
       "7   NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...   \n",
       "8   @PeeGee05 @MatrixETF @DEnergizer645 @anietieet...   \n",
       "10  Cant wait for #spacebapes \\n\\n#bapesclan #Meta...   \n",
       "15  @whitesandsgame @nftworldsNFT White Sands will...   \n",
       "16  @TAROVERSEcom I've participated with the rules...   \n",
       "17  In the world of #RadioactiveApes, don't forget...   \n",
       "18  âœ… Follow us to grab your monster when it's on ...   \n",
       "20  @mayordraw @_BillionAireSon @LadyofCrypto1 @Da...   \n",
       "21  Boars Lost in Art ğŸ— ğŸ¨ ğŸ–¼\\n\\n555 AI Generated #N...   \n",
       "22  @metaturca #MiniKishu is the next BIG project ...   \n",
       "23  @ConnectorCoin bringing celebrities onboard fr...   \n",
       "24  @LycanFinance #MiniKishu is the next BIG proje...   \n",
       "25  THIS PIECE NEEDS A BUYER ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\\n\\nGASLESS store...   \n",
       "27  THIS PIECE NEEDS A BUYER ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\\n\\nGASLESS store...   \n",
       "28  @FeggyPebbles @binance @FEGchris @Crypt0mummy ...   \n",
       "30  #NFTMarketplace launch tomorrow!  #Yawp ğŸš€  #IB...   \n",
       "\n",
       "                                             hashtags               source  \\\n",
       "1       ['Bapesclan', 'BapesMetavestor', 'Metaverse']      Twitter Web App   \n",
       "2                                                 NaN  Twitter for Android   \n",
       "3                                                 NaN      Twitter Web App   \n",
       "5           ['MiniKishu', 'BSC', 'gaming', 'staking']   Twitter for iPhone   \n",
       "7                                                 NaN   Twitter for iPhone   \n",
       "8                                ['MiniKishu', 'BSC']   Twitter for iPhone   \n",
       "10  ['spacebapes', 'bapesclan', 'Metaverse', 'bape...      Twitter Web App   \n",
       "15                                      ['Metaverse']      Twitter Web App   \n",
       "16                                                NaN      Twitter Web App   \n",
       "17  ['RadioactiveApes', 'nfts', 'NFTCommunity', '3...  Twitter for Android   \n",
       "18                                                NaN     MetaMonstersClub   \n",
       "20                                                NaN   Twitter for iPhone   \n",
       "21                                           ['NFTs']      Twitter Web App   \n",
       "22   ['MiniKishu', 'BSC', 'gaming', 'staking', 'NFT']   Twitter for iPhone   \n",
       "23                                                NaN  Twitter for Android   \n",
       "24          ['MiniKishu', 'BSC', 'gaming', 'staking']   Twitter for iPhone   \n",
       "25  ['NFT', 'NFTs', 'nftcollector', 'NFTinvestor',...   Twitter for iPhone   \n",
       "27  ['NFT', 'NFTs', 'nftcollector', 'NFTinvestor',...   Twitter for iPhone   \n",
       "28                                                NaN   Twitter for iPhone   \n",
       "30              ['NFTMarketplace', 'Yawp', 'IBCgang']   Twitter for iPhone   \n",
       "\n",
       "    is_retweet  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "5        False  \n",
       "7        False  \n",
       "8        False  \n",
       "10       False  \n",
       "15       False  \n",
       "16       False  \n",
       "17       False  \n",
       "18       False  \n",
       "20       False  \n",
       "21       False  \n",
       "22       False  \n",
       "23       False  \n",
       "24       False  \n",
       "25       False  \n",
       "27       False  \n",
       "28       False  \n",
       "30       False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" #emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" #symbols & Pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" #transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" #flags IOS\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "df[\"user_location\"] = df[\"user_location\"].map(lambda x: remove_emoji(x))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8b55d-7b9a-4af9-9fc8-edb940ca79e5",
   "metadata": {},
   "source": [
    "Using GeoPy API to get coordinates of locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f1e98e-5021-4178-8793-8fd1117e09c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 97/530 [04:45<21:39,  3.00s/it]Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=East+Java%2C+Indonesia&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=East+Java%2C+Indonesia&format=json&limit=1&accept-language=en\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                             | 150/530 [07:24<19:04,  3.01s/it]Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (0/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (1/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (2/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (3/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (4/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter swallowed an error after 5 retries. Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      " 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            | 151/530 [08:14<1:47:53, 17.08s/it]Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (0/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (1/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (2/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (3/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter caught an error, retrying (4/5 tries). Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en\n",
      "RateLimiter swallowed an error after 5 retries. Called with (*('Central Region, Singapore',), **{'language': 'en'}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 1348, in getresponse\n",
      "    response.begin()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 316, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/http/client.py\", line 277, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 447, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 336, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 783, in urlopen\n",
      "    return self.urlopen(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 574, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 448, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in get\n",
      "    return self.request('GET', url, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 438, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "  File \"/Users/gabriella/opt/anaconda3/lib/python3.8/site-packages/geopy/adapters.py\", line 460, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Central+Region%2C+Singapore&format=json&limit=1&accept-language=en (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 530/530 [27:57<00:00,  3.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duncs</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>NFT's + Crypto + Metaverse + Outdoors + Goodtimes</td>\n",
       "      <td>2012-11-28 01:47:19+00:00</td>\n",
       "      <td>745</td>\n",
       "      <td>1363</td>\n",
       "      <td>2583</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:33+00:00</td>\n",
       "      <td>Can't wait to hear this #Bapesclan \\n\\n#BapesM...</td>\n",
       "      <td>['Bapesclan', 'BapesMetavestor', 'Metaverse']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(Melbourne, City of Melbourne, Victoria, Austr...</td>\n",
       "      <td>(-37.8142176, 144.9631608, 0.0)</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Putik Gita</td>\n",
       "      <td>Banyuwangi, Indonesia</td>\n",
       "      <td>just ordinary woman</td>\n",
       "      <td>2016-04-07 03:31:10+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>130</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:26+00:00</td>\n",
       "      <td>@SuperStarPad @binance @Nuls good project.. ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "      <td>(Banyuwangi, East Java, Indonesia, (-8.2094973...</td>\n",
       "      <td>(-8.2094973, 114.3737201, 0.0)</td>\n",
       "      <td>Banyuwangi</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘</td>\n",
       "      <td>Dhaka, Bangladesh</td>\n",
       "      <td>ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...</td>\n",
       "      <td>2021-10-15 18:21:33+00:00</td>\n",
       "      <td>2355</td>\n",
       "      <td>3349</td>\n",
       "      <td>8550</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:13+00:00</td>\n",
       "      <td>Starts Trading on Uniswap and XT Exchanges Feb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(Dhaka, Dhaka Metropolitan, Dhaka District, Dh...</td>\n",
       "      <td>(23.7861979, 90.4026151, 0.0)</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LyxoğŸŒ¿ğŸŒ¿</td>\n",
       "      <td>Uyo,Akwa Ibom</td>\n",
       "      <td>Anatomist||Man utd faithful || Music freak || ...</td>\n",
       "      <td>2019-09-16 00:42:59+00:00</td>\n",
       "      <td>849</td>\n",
       "      <td>94</td>\n",
       "      <td>26422</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:59:04+00:00</td>\n",
       "      <td>@supertobi64 #MiniKishu is the next BIG projec...</td>\n",
       "      <td>['MiniKishu', 'BSC', 'gaming', 'staking']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>(Akwa Ibom, Abak Road, Ediene, Abak, Akwa Ibom...</td>\n",
       "      <td>(4.9408638, 7.8412267, 0.0)</td>\n",
       "      <td>Akwa Ibom</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...</td>\n",
       "      <td>2013-06-03 18:46:28+00:00</td>\n",
       "      <td>3965</td>\n",
       "      <td>4975</td>\n",
       "      <td>119194</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 23:58:57+00:00</td>\n",
       "      <td>NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>(Atlanta, Fulton County, Georgia, United State...</td>\n",
       "      <td>(33.7489924, -84.3902644, 0.0)</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AsianpettğŸ…°ï¸ ğŸ•Šï¸ âšª</td>\n",
       "      <td>Akwa Ibom, Nigeria</td>\n",
       "      <td>graphics designer\\nâœï¸ . Personal Art | Cover A...</td>\n",
       "      <td>2020-06-16 20:09:17+00:00</td>\n",
       "      <td>507</td>\n",
       "      <td>1228</td>\n",
       "      <td>3826</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 22:08:45+00:00</td>\n",
       "      <td>@AltcoinDailyio I really do believe in @YOMeta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "      <td>(Akwa Ibom, Nigeria, (4.9880607, 7.79517827785...</td>\n",
       "      <td>(4.9880607, 7.795178277855076, 0.0)</td>\n",
       "      <td>Akwa Ibom</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Scorpion Design</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mathematical Physicist. Digital art, conceptua...</td>\n",
       "      <td>2014-05-10 16:10:39+00:00</td>\n",
       "      <td>7860</td>\n",
       "      <td>7914</td>\n",
       "      <td>9994</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 22:08:42+00:00</td>\n",
       "      <td>Check out this new digital art that I uploaded...</td>\n",
       "      <td>['art']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(United Kingdom, (54.7023545, -3.2765753))</td>\n",
       "      <td>(54.7023545, -3.2765753, 0.0)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Scorpion Design</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mathematical Physicist. Digital art, conceptua...</td>\n",
       "      <td>2014-05-10 16:10:39+00:00</td>\n",
       "      <td>7860</td>\n",
       "      <td>7914</td>\n",
       "      <td>9994</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 22:08:34+00:00</td>\n",
       "      <td>Check out this new digital art that I uploaded...</td>\n",
       "      <td>['art']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(United Kingdom, (54.7023545, -3.2765753))</td>\n",
       "      <td>(54.7023545, -3.2765753, 0.0)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Scorpion Design</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mathematical Physicist. Digital art, conceptua...</td>\n",
       "      <td>2014-05-10 16:10:39+00:00</td>\n",
       "      <td>7860</td>\n",
       "      <td>7914</td>\n",
       "      <td>9994</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 22:08:18+00:00</td>\n",
       "      <td>Check out this new digital art that I uploaded...</td>\n",
       "      <td>['art']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(United Kingdom, (54.7023545, -3.2765753))</td>\n",
       "      <td>(54.7023545, -3.2765753, 0.0)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Scorpion Design</td>\n",
       "      <td>UK</td>\n",
       "      <td>Mathematical Physicist. Digital art, conceptua...</td>\n",
       "      <td>2014-05-10 16:10:39+00:00</td>\n",
       "      <td>7860</td>\n",
       "      <td>7914</td>\n",
       "      <td>9994</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-02-27 22:08:09+00:00</td>\n",
       "      <td>Check out this new digital art that I uploaded...</td>\n",
       "      <td>['art']</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>(United Kingdom, (54.7023545, -3.2765753))</td>\n",
       "      <td>(54.7023545, -3.2765753, 0.0)</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>530 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_name          user_location  \\\n",
       "1               Duncs   Melbourne, Australia   \n",
       "2          Putik Gita  Banyuwangi, Indonesia   \n",
       "3       ğŸ‘ğ—”ğ—•ğ—— ğ—–ğ—« ğŸğŸğŸğŠğŸ‘      Dhaka, Bangladesh   \n",
       "5              LyxoğŸŒ¿ğŸŒ¿          Uyo,Akwa Ibom   \n",
       "7             ğŸˆ¹ã„’å±±|å‡ ğŸˆ¯ï¸            Atlanta, GA   \n",
       "..                ...                    ...   \n",
       "995  AsianpettğŸ…°ï¸ ğŸ•Šï¸ âšª     Akwa Ibom, Nigeria   \n",
       "996   Scorpion Design                     UK   \n",
       "997   Scorpion Design                     UK   \n",
       "998   Scorpion Design                     UK   \n",
       "999   Scorpion Design                     UK   \n",
       "\n",
       "                                      user_description  \\\n",
       "1    NFT's + Crypto + Metaverse + Outdoors + Goodtimes   \n",
       "2                                  just ordinary woman   \n",
       "3    ğŸ‘ğŸŒ±ğŸ‘ğ…ğğ‹ğ‹ğğ– ğŒğ„ ğŸ‘ğŸŒ±ğŸ‘\\nğˆ ğ…ğğ‹ğ‹ğğ– ğğ€ğ‚ğŠ ğ…ğ€ğ’ğ“ğŸ‘ğŸğŸğŸ%ğˆğ…ğğŸ‘\\...   \n",
       "5    Anatomist||Man utd faithful || Music freak || ...   \n",
       "7    ğ•‹ğ•šğ•ğ•ğ•šğ•š TÌ†Ìˆğ™¬ğ™ğ™£TÌ‘Ìˆğ™¬ğ™ğ™£ || This the link: https://...   \n",
       "..                                                 ...   \n",
       "995  graphics designer\\nâœï¸ . Personal Art | Cover A...   \n",
       "996  Mathematical Physicist. Digital art, conceptua...   \n",
       "997  Mathematical Physicist. Digital art, conceptua...   \n",
       "998  Mathematical Physicist. Digital art, conceptua...   \n",
       "999  Mathematical Physicist. Digital art, conceptua...   \n",
       "\n",
       "                  user_created  user_followers  user_friends  user_favourites  \\\n",
       "1    2012-11-28 01:47:19+00:00             745          1363             2583   \n",
       "2    2016-04-07 03:31:10+00:00              21           130               65   \n",
       "3    2021-10-15 18:21:33+00:00            2355          3349             8550   \n",
       "5    2019-09-16 00:42:59+00:00             849            94            26422   \n",
       "7    2013-06-03 18:46:28+00:00            3965          4975           119194   \n",
       "..                         ...             ...           ...              ...   \n",
       "995  2020-06-16 20:09:17+00:00             507          1228             3826   \n",
       "996  2014-05-10 16:10:39+00:00            7860          7914             9994   \n",
       "997  2014-05-10 16:10:39+00:00            7860          7914             9994   \n",
       "998  2014-05-10 16:10:39+00:00            7860          7914             9994   \n",
       "999  2014-05-10 16:10:39+00:00            7860          7914             9994   \n",
       "\n",
       "     user_verified                       date  \\\n",
       "1            False  2022-02-27 23:59:33+00:00   \n",
       "2            False  2022-02-27 23:59:26+00:00   \n",
       "3            False  2022-02-27 23:59:13+00:00   \n",
       "5            False  2022-02-27 23:59:04+00:00   \n",
       "7            False  2022-02-27 23:58:57+00:00   \n",
       "..             ...                        ...   \n",
       "995          False  2022-02-27 22:08:45+00:00   \n",
       "996          False  2022-02-27 22:08:42+00:00   \n",
       "997          False  2022-02-27 22:08:34+00:00   \n",
       "998          False  2022-02-27 22:08:18+00:00   \n",
       "999          False  2022-02-27 22:08:09+00:00   \n",
       "\n",
       "                                                  text  \\\n",
       "1    Can't wait to hear this #Bapesclan \\n\\n#BapesM...   \n",
       "2    @SuperStarPad @binance @Nuls good project.. ho...   \n",
       "3    Starts Trading on Uniswap and XT Exchanges Feb...   \n",
       "5    @supertobi64 #MiniKishu is the next BIG projec...   \n",
       "7    NFT community!!! ğŸ“£\\nYa go follow @twin_nfts. W...   \n",
       "..                                                 ...   \n",
       "995  @AltcoinDailyio I really do believe in @YOMeta...   \n",
       "996  Check out this new digital art that I uploaded...   \n",
       "997  Check out this new digital art that I uploaded...   \n",
       "998  Check out this new digital art that I uploaded...   \n",
       "999  Check out this new digital art that I uploaded...   \n",
       "\n",
       "                                          hashtags               source  \\\n",
       "1    ['Bapesclan', 'BapesMetavestor', 'Metaverse']      Twitter Web App   \n",
       "2                                              NaN  Twitter for Android   \n",
       "3                                              NaN      Twitter Web App   \n",
       "5        ['MiniKishu', 'BSC', 'gaming', 'staking']   Twitter for iPhone   \n",
       "7                                              NaN   Twitter for iPhone   \n",
       "..                                             ...                  ...   \n",
       "995                                            NaN  Twitter for Android   \n",
       "996                                        ['art']      Twitter Web App   \n",
       "997                                        ['art']      Twitter Web App   \n",
       "998                                        ['art']      Twitter Web App   \n",
       "999                                        ['art']      Twitter Web App   \n",
       "\n",
       "     is_retweet                                           location  \\\n",
       "1         False  (Melbourne, City of Melbourne, Victoria, Austr...   \n",
       "2         False  (Banyuwangi, East Java, Indonesia, (-8.2094973...   \n",
       "3         False  (Dhaka, Dhaka Metropolitan, Dhaka District, Dh...   \n",
       "5         False  (Akwa Ibom, Abak Road, Ediene, Abak, Akwa Ibom...   \n",
       "7         False  (Atlanta, Fulton County, Georgia, United State...   \n",
       "..          ...                                                ...   \n",
       "995       False  (Akwa Ibom, Nigeria, (4.9880607, 7.79517827785...   \n",
       "996       False         (United Kingdom, (54.7023545, -3.2765753))   \n",
       "997       False         (United Kingdom, (54.7023545, -3.2765753))   \n",
       "998       False         (United Kingdom, (54.7023545, -3.2765753))   \n",
       "999       False         (United Kingdom, (54.7023545, -3.2765753))   \n",
       "\n",
       "                             coordinates           state         country  \n",
       "1        (-37.8142176, 144.9631608, 0.0)       Melbourne       Australia  \n",
       "2         (-8.2094973, 114.3737201, 0.0)      Banyuwangi       Indonesia  \n",
       "3          (23.7861979, 90.4026151, 0.0)           Dhaka      Bangladesh  \n",
       "5            (4.9408638, 7.8412267, 0.0)       Akwa Ibom         Nigeria  \n",
       "7         (33.7489924, -84.3902644, 0.0)         Atlanta   United States  \n",
       "..                                   ...             ...             ...  \n",
       "995  (4.9880607, 7.795178277855076, 0.0)       Akwa Ibom         Nigeria  \n",
       "996        (54.7023545, -3.2765753, 0.0)  United Kingdom  United Kingdom  \n",
       "997        (54.7023545, -3.2765753, 0.0)  United Kingdom  United Kingdom  \n",
       "998        (54.7023545, -3.2765753, 0.0)  United Kingdom  United Kingdom  \n",
       "999        (54.7023545, -3.2765753, 0.0)  United Kingdom  United Kingdom  \n",
       "\n",
       "[530 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ref: https://geopy.readthedocs.io/en/stable/#usage-with-pandas\n",
    "geolocator = Nominatim(user_agent='my_email@myserver.com')\n",
    "\n",
    "#Currently Have a weird Rate Limiter error not sure what to do \n",
    "\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=3, max_retries=5)\n",
    "df[\"location\"] = df[\"user_location\"].progress_apply(geocode, language=\"en\") # Some locations are in hindi, chinese. Language=â€™enâ€™ returns location in english\n",
    "df[\"coordinates\"] = df[\"location\"].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "df[\"state\"] = df[\"location\"].apply(lambda loc: loc[0].split(\",\")[0] if loc else None)\n",
    "df[\"country\"] = df[\"location\"].apply(lambda loc: loc[0].split(\",\")[-1] if loc else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46079d48-dfa8-471f-9914-a28b8359ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_305152345f214741ac42aa83853b80da%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_305152345f214741ac42aa83853b80da%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_305152345f214741ac42aa83853b80da%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_305152345f214741ac42aa83853b80da%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B13.133932434766733%2C%2016.103938729508073%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%202%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_f7373d35fb904921b54c240d2932f87f%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Data%20by%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22http%3A//openstreetmap.org%5C%22%5Cu003eOpenStreetMap%5Cu003c/a%5Cu003e%2C%20under%20%5Cu003ca%20href%3D%5C%22http%3A//www.openstreetmap.org/copyright%5C%22%5Cu003eODbL%5Cu003c/a%5Cu003e.%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_305152345f214741ac42aa83853b80da%29%3B%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fbacd721310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('metaverse_tweets_final.csv', encoding='utf-8', index = False)\n",
    "\n",
    "my_map = folium.Map(\n",
    "    location=[13.133932434766733, 16.103938729508073],\n",
    "    zoom_start=2)\n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d6b6121-b68c-49c9-a992-4fcc9d9b1af0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'coordinates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coordinates'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cl/z23bldmj68j_l7xncc6br50h0000gp/T/ipykernel_29566/3210658665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(row['coordinates'], row['user_location'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     folium.Marker(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coordinates'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = df[df['coordinates'].notna()]\n",
    "for index, row in df.iterrows():\n",
    "    #print(row['coordinates'], row['user_location'])\n",
    "    lat, lon, _ = row['coordinates']\n",
    "    folium.Marker(\n",
    "        location = [lat, lon],\n",
    "        popup= row['user_location'],\n",
    "        tooltip = row['user_location'],\n",
    "    ).add_to(my_map)\n",
    "    \n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaa057-cd7c-435f-85da-ecb16e60e7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0f3c4-84f3-45d4-b4d2-3729917f587b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269e9c4-bea3-417c-8ce1-708ff091a59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9041ad0-9602-49bd-8a18-faf44fe62711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
